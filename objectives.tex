%
% objectives.tex
%

As with most software design projects, our architecture was created to offer a reusable solution to a set of common problems.  Akin to a software design pattern or architecture, this thesis presents a general-purpose architecture to solve the common problems faced in web-based interactive data visualization applications in a general, adaptable, and reusable way.  This section will overview the common problems that inspired the creation of a common-use architecture. \par

\section{Data Scaling}
The primary limiting factor for a web-based data visualization is its platform.  Web-based data visualizations are rendered in the web browser so the scale and interactivity of a data visualization is limited by the abilities of the client’s web browser and device.  If too many data points are rendered in a single webpage or visualization, especially interactive visualizations, the experience can become laggy, unresponsive, or even cause issues with the web browser.  As a result, the application must limit the number of rendered data points within a given browser window to provide a fluid and responsive experience. This limitation creates the problem of data scaling. Data scaling refers to the process of aggregating, summarizing, or otherwise reducing the number of data points from a given input to some smaller output.  For example, if a given dataset contains five thousand unique points but the browser can only render approximately one thousand points before its performance degrades, the dataset has to be aggregated or scaled to one thousand points before visualization. \par
Ideally, the data scaling process should attempt to show as much detail in the visualization as possible, without sacrificing responsiveness and fluidity in the live visualization.  An ideal visualization application would allow the user to focus in on a subset of visualized data and view that subset in more detail.  This indicates a need for adaptable scalability.  Recall our earlier example which discussed a chart showing one thousand points aggregated from a five thousand point dataset.  Within this example, the user should be able to focus on 20\% of the dataset, equating to one thousand data points from the original dataset and two hundred data points from the aggregated set, and view all one thousand data points from the original dataset.  This illustrates adaptable data scaling, allowing the user to view a subset of the data in the greatest detail possible within the limitations of the web browser. \par
The data scaling process should also minimize impacts on the application’s loading time and performance demand on the client’s device.  If the data scaling process improves the fluidity of the data visualization but causes the application to take an additional ten seconds to load a dataset, other visualization or scaling means should be considered.  Alternative scaling methods should usually be considered if they affect the loading time such that additional latency accommodations should be made.  Specifically, if the addition of a certain data scaling method causes the system to take more than 10 seconds, either a progress bar must be added or data scaling must be optimized \cite{doet, aboutface}.  Another concern arises if the data scaling process is executed on the client’s web browser where the speed of the scaling process will depend on the capabilities of the client’s device.  In this case the scaling process will could potentially affect the client’s device performance and, in the worst case, cause the web browser to become unresponsive. In the end, the primary goal of data scaling is to improve the responsiveness of an in-browser data visualization without greatly compromising detail and to do so with minimal effect on the performance of the rest of the application. \par

\section{Data Sources}
Data sources are a common avenue for change in highly data-dependent web applications. An application may be paired with one or more database solution for local data storage and might even acquire data from remote sources through external web APIs.  As such, any architecture that seeks to generally accommodate data visualization must remain decoupled from data sources. An architecture shouldn’t be coupled to one database solution or remote API interface.  For example, a web application to provide weather data could either use a local MongoDB database for all of its data needs or it could use an SQL-based database to provide weather forecasts and acquire real-time temperature and wind data from a remote web API.  In this case, the architecture should allow the software developer to define these modes of data acquisition generically.  It is also ideal to encapsulate these data source and data interactions as they are likely to change later.  Given that web API’s tend to change format or location, data sources should have a clear location for change which is isolated from the rest of the application. The architecture can also use this abstraction to enforce solutions to other common problems such as data scaling and transmission. \par

\section{Data Transmission}
Server to client data transmission is a core function of any web-based data visualization application.  Any web application that wishes to visualize data on a web client must first transmit that visualizable data from a web server to the client. Different modes for data communication exist and must be accomodated.  The two primary modes for communication over the web are through HTTP requests and WebSockets.  Both of these methods have seen widespread use and thus both must be accommodated and leveraged by any general-purpose architecture.  The issue of data transmission is an issue of encapsulation.  The mode of data transmission should be encapsulated to ensure that the architecture is flexible to the needs of a developer.   In some extreme cases, an application may pivot from a HTTP request based data transmission system to a WebSocket-based transmission system or vice versa.  These changes should be modular and isolated from the remainder of the application.  An architecture should encapsulate data transmission methods into one location and make an effort to decouple data transmission from any control logic for data acquisition. \par
Server to client data transmission is important, but if the data received by the client isn’t in a format comprehensible by the client, the data is useless.  The server and the client should both obey some standard format for data communications such that a change on one end of the data transmission should not break functionality on the other end.  For example, if the name of a data field changes and the client is tightly coupled to the naming scheme of transmitted data fields, the client will break.  This can also lead to errors that are hard to debug, where data is received by the client but not interpreted properly.  As such, any architecture should include a means of predictable data formatting such that the server can rely on a certain request format from the client and the client can rely on a certain response format from the server.  That being said, the server and client should adapt to new datasets with minimal changes. Data transmission formatting is a difficult problem, but the creation of a standard can aid in writing adaptable code. \par
Beyond data transmission formatting, the server must also optimize its responses for size efficiency and quick transmission.  This problem is twofold, responses should be as small as possible and renderable data should be sent to the client as quickly as possible.  The response size will be somewhat minimized by scaling data on the server-side as described in section 4.1.  By sending only the points that will be rendered by the client, the server can avoid transmitting unnecessary data.  As for renderable data, an architecture should have a means of prioritizing the fastest renderable response.  Data transmission not only relies on format, but also on speed and size. \par

\section{Dataset Filtering and Security}
Data security is an important issue for any web application, specifically for applications focused entirely around the transmission and visualization of data from a centralized provider. Any architecture can make simple architectural decisions to prevent common mistakes relating to data security.  One of the primary problems facing web servers is unsanitized user input.  In the case of any data visualization application, the client will issue a request to the server for data.  An architecture should enforce a standard method for request validation and ensure that the client doesn’t request or receive sensitive datasets. \par

\section{Charting Package Agnosticism}
The field of web development is filled with varying solutions for interactive and non-interactive chart creation, rendering, population, and management \cite{d3homepage, chartjs, highcharts, c3js, bokehjs}.  These libraries often focus on either specific differentiating features \cite{chartjs, highcharts}, simplicity \cite{chartjs, highcharts}, backend optimizations or accomodations \cite{bokehjs}, special dynamicity, or adaptability and flexibility \cite{d3homepage, c3js}. Charting libraries also appear, change, and disappear frequently as the area of web-based data visualization continues to grow and evolve.  As a result, an architecture for generalized web-based data visualization should be charting package/platform agnostic.  Specifically, charts should encapsulated.  As such, charts should be entirely separate from data acquisition and control logic for the data visualization page.  Charts still need to be able to dynamically request data for visualization and must also be updated when new data is available.  Finally, charts must be able to exist independently of one another, but must also have a means of interaction if the developer desires.  In essence, charts need to be individually encapsulated and defined in order to be charting platform agnostic, but there must exist a standardized “gatekeeper” or “driver” that interacts with the server and updates the charts.  The developer should be able to choose any charting package(s) of their choice and implement them freely while still obeying the architecture.  Ideally, charting package(s) and charts themselves should be easily interchangeable.  \par

\section{Dataset Loading and Processing}
A chart should only be rendered by the client if the server has provided all the necessary datasets.  It would seem logically obvious that a chart without data should not be show, but this adds certain requirements to chart encapsulation.  Given that a page may contain multiple charts, each chart must have a means of broadcasting the datasets it needs in order to be rendered.  It should be hidden until those datasets are provided.  As such, driver application code must include logic to check dataset availability, request only the necessary datasets, process the response, and only render charts which have all dataset requirements met. \par
